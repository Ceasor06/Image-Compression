# Image-Compression

![image](https://user-images.githubusercontent.com/105945382/211190641-a356c190-6744-4edb-9a61-f50a7e9e102a.png)

Image compression is minimizing the size in bytes of a graphics file without degrading the quality of the image to an unacceptable level. 
The reduction in file size allows more images to be stored in a given amount of disk or memory space.
It also reduces the time required for images to be sent over the Internet or downloaded from Web pages.
There are numerous picture compression algorithms available . Among all of these algorithms, in this project I used 3 algorithms implemented on colab and matlab.

## Following algorithms were used in this project:

- Huffman Algorithm

  - Huffman coding is one of the most widely used algorithms for compression of text, images, videos, etc. It encodes based on the probability of symbols, assigning a greater number of bits to symbols with lower probability, and lower number of bits to symbols with higher probability.

* Discrete Cosine Transform (DCT)
  
  - The DCT can be used to convert the signal (spatial information) into numeric data ("frequency" or "spectral" information) so that the image's information exists in a quantitative form that can be manipulated for compression. The signal for a graphical image can be thought of as a three-dimensional signal.

+ Convolutional Autoencoder
  
  - An autoencoder neural network is an Unsupervised Machine learning algorithm that applies backpropagation, setting the target values to be equal to the inputs. Autoencoders are used to reduce the size of our inputs into a smaller representation. If anyone needs the original data, they can reconstruct it from the compressed data.

<hr>
  
  
